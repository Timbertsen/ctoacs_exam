layers:
- filters: 32
  kernel_size: &id001 [3, 3]
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- filters: 32
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- filters: 32
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- pool_size: *id001
  type: MaxPooling2D
- filters: 64
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- filters: 64
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- filters: 64
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- pool_size: [2, 2]
  type: MaxPooling2D
- filters: 128
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- filters: 128
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- filters: 128
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- pool_size: [2, 2]
  type: MaxPooling2D
- filters: 128
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- filters: 128
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- filters: 128
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- pool_size: [2, 2]
  type: MaxPooling2D
- filters: 256
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- filters: 256
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- filters: 256
  kernel_size: *id001
  padding: same
  type: Conv2D
- type: BatchNormalization
- activation: relu
  type: Activation
- type: Flatten
- units: 254
  type: Dense
- type: BatchNormalization
- activation: relu
  type: Activation
- rate: 0.3
  type: Dropout
layers_before_output:
- units: 254
  type: Dense
- type: BatchNormalization
- activation: relu
  type: Activation
- units: 254
  type: Dense
- type: BatchNormalization
- activation: relu
  type: Activation
- units: 254
  type: Dense
- type: BatchNormalization
- activation: relu
  type: Activation
losses:
  out_class: categorical_crossentropy
  out_count: mean_squared_error
  out_location: mean_squared_error
metrics:
  out_class: categorical_accuracy
  out_count: mae
  out_location: iou
output_layers:
- activation: softmax
  name: out_class
  type: Dense
  units: 4
- activation: linear
  name: out_count
  type: Dense
  units: 1
- name: out_location
  type: Dense
  units: 4
type: cnn
